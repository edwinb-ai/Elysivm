var documenterSearchIndex = {"docs":
[{"location":"example1/","page":"Examples","title":"Examples","text":"EditURL = \"<unknown>/src/examples/example1.jl\"","category":"page"},{"location":"example1/#Example:-Case-study","page":"Examples","title":"Example: Case study","text":"","category":"section"},{"location":"example1/","page":"Examples","title":"Examples","text":"In this case study we will deal with the Wisconsin breat cancer dataset which can be browsed freely on the UCI website.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"In particular, this dataset contains 10 features and 699 instances. In the work we will do here, however, we will skip some instances due to some missing values.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"The dataset contains only two classes, and the purpose is to use all ten features to answer a simple question:","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Does the subject have a benign or malign tumor?","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"To answer this question, we will train a Least Squares Support Vector Machine as implemented in Elysivm.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"First, we need to import all the necessary packages.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"using MLJ, MLJBase\nusing DataFrames, CSV\nusing CategoricalArrays\nusing Random, Statistics\nimport Elysivm","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We then need to specify a seed to enable reproducibility of the results.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"rng = MersenneTwister(801239);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Here we are creating a list with all the headers.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"headers = [\n\t\"id\", \"Clump Thickness\",\n\t\"Uniformity of Cell Size\", \"Uniformity of Cell Shape\",\n\t\"Marginal Adhesion\", \"Single Epithelial Cell Size\",\n\t\"Bare Nuclei\", \"Bland Chromatin\",\n\t\"Normal Nucleoli\", \"Mitoses\", \"class\"\n];\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We define the path were the dataset is located","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"path = joinpath(\"examples\", \"wbc.csv\");\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We load the csv file and convert it to a DataFrame. Note that we are specifying to the file reader to replace the string ? to a missing value. This dataset contains the the string ? when there is a value missing.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"data = CSV.File(path; header=headers, missingstring=\"?\") |> DataFrame;\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We can display the first 10 rows from the dataset","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"first(data, 10)","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We can see that all the features have been added correctly, we can see that we have an unncessary feature called id, so we will remove it.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"select!(data, Not(:id));\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We also need to remove all the missing data from the DataFrame","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"data = dropmissing(data);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We need to encode the classes correctly. This implementation expects that both classes are either a 1 or a -1, so we replace them here.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"replace!(data.class, 2 => -1);\nreplace!(data.class, 4 => 1);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"The class column should be of type categorical, following the MLJ API, so we encode it here.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"transform!(data, :class => categorical, renamecols=false);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Check statistics per column.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"describe(data)","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Split the dataset into training and testing.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"y, X = unpack(data, ==(:class), colname -> true);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We will use only 2/3 for training.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"train, test = partition(eachindex(y), 2 / 3, shuffle=true, rng=rng);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Always remove mean and set the standard deviation to 1.0 when dealing with SVMs.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"stand1 = Standardizer(count=true);\nX = MLJBase.transform(fit!(machine(stand1, X)), X);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Check statistics per column again to ensure standardization, but remember to do it now with the X matrix.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"describe(X)","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Good, now every column has a mean very close to zero, so the standardization was done correctly.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We now create our model with Elysivm","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"model = Elysivm.LSSVClassifier();\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"These are the values for the hyperparameter grid search. We need to find the best subset from this set of parameters. Although I will not do this here, the best approach is to find a set of good hyperparameters and then refine the search space around that set. That way we can ensure we will always get the best results.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"sigma_values = [0.5, 5.0, 10.0, 15.0, 25.0, 50.0, 100.0, 250.0, 500.0];\nr1 = MLJBase.range(model, :σ, values=sigma_values);\ngamma_values = [0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0];\nr2 = MLJBase.range(model, :γ, values=gamma_values);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We now create a TunedModel that will use a 10-folds stratified cross validation scheme in order to find the best set of hyperparameters. The stratification is needed because the classes are somewhat imbalanced:","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Benign: 458 (65.5%)\nMalignant: 241 (34.5%)","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"self_tuning_model = TunedModel(\n    model=model,\n    tuning=Grid(rng=rng),\n    resampling=StratifiedCV(nfolds=10),\n    range=[r1, r2],\n    measure=accuracy,\n    acceleration=CPUThreads(), # We use this to enable multithreading\n);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Once the best model is found, we create a machine with it, and fit it","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"mach = machine(self_tuning_model, X, y);\nfit!(mach, rows=train, verbosity=0);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"We can now show the best hyperparameters found.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"fitted_params(mach).best_model","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"And we test the trained model. We expect somewhere around 94%-96% accuracy.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"results = predict(mach, rows=test);\nacc = accuracy(results, y[test]);\nnothing #hide","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"Show the accuracy for the testing set","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"println(acc * 100.0)","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"As you can see, it is fairly easy to use Elysivm together with MLJ. We got a good accuracy result and this proves that the implementation is actually correct. This dataset is commonly used as a benchmark dataset to test new algorithms.","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"","category":"page"},{"location":"example1/","page":"Examples","title":"Examples","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Types","page":"Reference","title":"Types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Elysivm]\nPages = [\"types.jl\"]","category":"page"},{"location":"reference/#Elysivm.KernelRBF","page":"Reference","title":"Elysivm.KernelRBF","text":"KernelRBF\n\nThis type is to compute the RBF kernel defined as\n\nK(xy)=expleft( -vert x - yvert^2 gamma right)\n\nwhere vert x - yvert is the Euclidean norm. This norm is computed with the Kernels.jl package.\n\nFields\n\nγ::Real: The hyperparameter associated with the RBF kernel.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Elysivm.KernelRBF-Tuple{AbstractArray{T,2} where T,Float64}","page":"Reference","title":"Elysivm.KernelRBF","text":"KernelRBF(x::AbstractMatrix, gamma::Float64)\nKernelRBF(x, y::AbstractMatrix, gamma::Float64)\nKernelRBF(x, y::AbstractVector, gamma::Float64)\n\nDepending on the arguments, it computes either a pairwise RBF kernel (if it is only with one matrix), or a pairwise RBF kernel between a matrix and an array.\n\nArguments\n\nx::AbstractMatrix: A two-row matrix.\ny::AbstractVector: A one dimensional array.\ngamma::Float64: The hyperparameter needed to compute the kernel.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Elysivm.LSSVC","page":"Reference","title":"Elysivm.LSSVC","text":"LSSVC()\nLSSVC(; kernel=\"rbf\", γ=1.0, σ=1.0)\n\nThe type to hold a Least Squares Support Vector Classifier.\n\nFields\n\nkernel::String: The kind of kernel to use for the non-linear mapping of the data.\nγ::Float64: The gamma hyperparameter that is intrinsic of the Least Squares version of the Support Vector Machines.\nσ::Float64: The hyperparameter for the RBF kernel.\n\nKeywords\n\nkernel: A string to denote the kernel to be used.\nγ: A float value to assign the gamma hyperparameter.\nσ: A float value to assign the sigma hyperparameter.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Elysivm.SVM","page":"Reference","title":"Elysivm.SVM","text":"SVM\n\nA super type for both classifiers and regressors that are implemented as Support Vector Machines.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Methods","page":"Reference","title":"Methods","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Elysivm]\nPages = [\"training.jl\"]","category":"page"},{"location":"reference/#Elysivm.build_omega-Tuple{AbstractArray{T,2} where T,AbstractArray{T,1} where T}","page":"Reference","title":"Elysivm.build_omega","text":"build_omega(x::AbstractMatrix, y::AbstractVector, sigma::Float64;\n    kernel::String=\"rbf\") -> AbstractMatrix\n\nIt builds a matrix, known as the \"omega matrix\", that contains the following information\n\nOmega_kl = y_k y_l K(x_k x_l)\n\nwith kl=1dotsN, and N being the length of x. In other words, the number of training instances.\n\nThis matrix contains information about the mapping to a new space using the kernel. It is exclusively used in the training step of the learning procedure.\n\nArguments\n\nx::AbstractMatrix: The data matrix with the training instances.\ny::AbstractVector: The labels for each of the instances in x.\n\nKeywords\n\nkernel::String=\"rbf\": The kernel to be used. For now, only the RBF kernel is implemented.\nsigma::Float64: The hyperparameter for the RBF kernel.\n\nReturns\n\nΩ: The omega matrix computed as shown above.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Elysivm.svmpredict-Tuple{LSSVC,Any,AbstractArray{T,2} where T}","page":"Reference","title":"Elysivm.svmpredict","text":"svmpredict(svm::LSSVC, fits, xnew::AbstractMatrix) -> AbstractArray\n\nUses the information obtained from svmtrain such as the bias and weights to construct a decision function and predict new class values.\n\nArguments\n\nsvm::LSSVC: The Support Vector Machine that contains the hyperparameters, as well as the kernel to be used.\nfits: It can be any container data structure but it must have four elements: x, the data matrix; y, the labels vector; α, the weights; and b, the bias.\nxnew::AbstractMatrix: The data matrix that contains the new instances to be predicted.\n\nReturns\n\nArray: The labels corresponding to the prediction to each of the instances in xnew.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Elysivm.svmtrain-Tuple{LSSVC,AbstractArray{T,2} where T,AbstractArray{T,1} where T}","page":"Reference","title":"Elysivm.svmtrain","text":"svmtrain(svm::LSSVC, x::AbstractMatrix, y::AbstractVector) -> Tuple\n\nSolves a Least Squares Support Vector Classification problem using the Conjugate Gradient method. In particular, it uses the Lanczos version due to the fact that the matrices are symmetric.\n\nArguments\n\nsvm::LSSVC: The Support Vector Machine that contains the hyperparameters, as well as the kernel to be used.\nx::AbstractMatrix: The data matrix with the features. It is expected that this array is already standardized, i.e. the mean for each feature is zero and its standard deviation is one.\ny::AbstractVector: A vector that contains the classes. It is expected that there are only two classes, -1 and 1.\n\nReturns\n\nTuple: A tuple containing x, y and the following two elements:\nb: Contains the bias for the decision function.\nα: Contains the weights for the decision function.\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Elysivm","category":"page"},{"location":"#Elysivm","page":"Home","title":"Elysivm","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is Elysivm, a Least Squares Support Vector Machine implementation in pure Julia. It is meant to be used together with the fantastic MLJ.jl Machine Learning framework.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Check out the Examples section to see how to use it together with MLJ.","category":"page"},{"location":"#Formulation","page":"Home","title":"Formulation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"WIP","category":"page"},{"location":"#Integration","page":"Home","title":"Integration","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"WIP","category":"page"}]
}
